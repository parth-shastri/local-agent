
 **Local Agent Project**
=======================

A fun learning project to run agents locally by building them from scratch.
This repo currently supports a simple `FunctionCallingAgent` class, but it can be extended to more complex & different agents. The main goal is to learn how agents & tool calling in LLMs works.

**What is this project about?**
-----------------------------

This project allows me to run agents locally on my machine, using language models like LLaMA, Groq, and Ollama. I've created a simple framework to get started, and I'm experimenting with different models and tools to see what works best.

**Key Features:**

* Run agents locally on my machine
* Support for multiple language models (LLaMA, Groq, Ollama)
* Simple framework to get started
* Experiment with different tools and models

**Why am I using this project?**
---------------------------------

* I wanted to learn how agents & tool calling in LLMs works.
* I'm experimenting with different models and tools
* I wanted build & run agents using just the different model services, locally.

**Getting Started:**
-------------------

1. Clone the repository
2. Install the required dependencies
3. Run one of the `.sh` files to get started

**Contributing:**
----------------

I welcome contributions and feedback! If you have any ideas or suggestions, feel free to open an issue or pull request.
